{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used packages\n",
    "from preprocess import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from preprocess import preprocessing\n",
    "from preparation import preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plots the confussion matrix from our system results\n",
    "\n",
    "Receives a vector with the system results and another one with the actual results\n",
    "Does not return anything but it displays the confussion matrix\n",
    "'''\n",
    "def print_confussion_matrix(y_test, y_pred):\n",
    "    sns.heatmap((confusion_matrix(y_test,y_pred)), annot=True, fmt=\"d\",cmap=\"crest\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "Builds a dictionary with the word frequency counts of a string\n",
    "\n",
    "Receives a preprocessed text\n",
    "Returns a dictionary with the word frequency counts\n",
    "'''\n",
    "def build_word_frequency_histogram(preprocessed_str):\n",
    "    wordfreq = {}\n",
    "\n",
    "    # If word has already been found, add 1 to its count. If not, add the word to the dictionary\n",
    "    for word in preprocessed_str.split():\n",
    "        if word not in wordfreq:\n",
    "            wordfreq[word] = 0\n",
    "        wordfreq[word] += 1\n",
    "    return wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creates subplots and displays all bar charts of histograms\n",
    "\n",
    "Receives all the system results\n",
    "Does not return anything but it displays all the histograms, ROC Curve and Confussion Matrix\n",
    "'''\n",
    "def create_subplots(maxhistograms, maxfilename, fpr, tpr, actual_results, system_results):\n",
    "    fig, axs = plt.subplots(len(maxhistograms)+1, figsize=(10, 70))\n",
    "    fig.tight_layout(pad=10)\n",
    "    for i, histogram in enumerate(maxhistograms):\n",
    "        categories = list(histogram.keys())[:20]\n",
    "        frequencies = list(histogram.values())[:20]\n",
    "        axs[i].bar(categories, frequencies)            \n",
    "        axs[i].set_xlabel('Categories')\n",
    "        axs[i].set_ylabel('Frequency')\n",
    "        axs[i].set_title(f'Word frequency histogram for {maxfilename[i]}')\n",
    "        axs[i].tick_params(axis='x', rotation=90)\n",
    "\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel(\"Error\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()\n",
    "    print_confussion_matrix(actual_results, system_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores all the plagiarism results for every comparison\n",
    "dictPlag = {}\n",
    "\n",
    "# Actual results of our tests. 1 = Plagiarism, 0 = Original\n",
    "actual_results = [1,1,0,0,1,1,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "# Results found by our system when doing the plagiarism analysis\n",
    "system_results = []\n",
    "\n",
    "'''\n",
    "Main decision function \n",
    "'''\n",
    "def decision(filePathOriginals, filePathSuspicious):\n",
    "   \n",
    "    # Preprocessing original texts\n",
    "    original_texts = [file for file in os.listdir(filePathOriginals) if os.path.isfile(os.path.join(filePathOriginals, file))]\n",
    "    processed_original_texts = []\n",
    "    for original_text in original_texts:\n",
    "        processed_original_texts.append(preprocessing(filePathOriginals + \"/\" + original_text))\n",
    "\n",
    "    print(\"Starting plagiarism detection...\")\n",
    "    print(\"\\n\")\n",
    "    # Preprocessing suspicious texts\n",
    "    suspicious_texts = [file for file in os.listdir(filePathSuspicious) if os.path.isfile(os.path.join(filePathSuspicious, file))]\n",
    "    processed_suspicious_texts = []\n",
    "    for suspicious_text in suspicious_texts:\n",
    "        processed_suspicious_texts.append(preprocessing(filePathSuspicious + \"/\" + suspicious_text))\n",
    "       \n",
    "    # Creating histograms for suspicious texts\n",
    "    maxplagiarism = [0 for _ in range(len(processed_suspicious_texts))]\n",
    "    maxhistograms = [{} for _ in range(len(processed_suspicious_texts))]\n",
    "    maxfilename = [\"\" for _ in range(len(processed_suspicious_texts))]\n",
    "    \n",
    "    # Comparing suspicious text with original texts\n",
    "    for k, processed_suspicious_text in enumerate(processed_suspicious_texts):\n",
    "        print(\"Suspicious text: \", suspicious_text)\n",
    "        plagiarized_check = False\n",
    "\n",
    "        # Comparing suspicious text with original texts\n",
    "        for i, processed_original_text in enumerate(processed_original_texts):\n",
    "            unigram_result, trigram_result = preparation(processed_suspicious_text, processed_original_text)\n",
    "\n",
    "            # Check if plagiarism is detected\n",
    "            if unigram_result > 0.15 and trigram_result > 0.15:\n",
    "                print(\"Plagiarism detected in file: \", original_texts[i])\n",
    "                print(\"⚠️ ⚠️ ⚠️ ⚠️ ⚠️ ⚠️\")\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                if dictPlag.get(suspicious_text) is None:\n",
    "                    dictPlag[suspicious_text] = [[original_texts[i],unigram_result,trigram_result]]\n",
    "                else:\n",
    "                    dictPlag[suspicious_text].append([original_texts[i], unigram_result,trigram_result])\n",
    "                    \n",
    "                # When plagiarism is detected, append 1 to system results\n",
    "                if not plagiarized_check:\n",
    "                    system_results.append(1)\n",
    "                    plagiarized_check = True\n",
    "                \n",
    "                # Check if plagiarism is the highest detected\n",
    "                if maxplagiarism[k] <= unigram_result:\n",
    "                    maxplagiarism[k] = unigram_result\n",
    "                    maxfilename[k] = suspicious_texts[k]\n",
    "                    maxhistograms[k] = build_word_frequency_histogram(processed_suspicious_text)\n",
    "                    \n",
    "        # When there is no plagiarism, append 0 to system results\n",
    "        if not plagiarized_check:\n",
    "            system_results.append(0)\n",
    "\n",
    "\n",
    "    # Remove empty histograms\n",
    "    maxhistograms = [histogram for histogram in maxhistograms if histogram]\n",
    "    maxfilename = [filename for filename in maxfilename if filename]\n",
    "\n",
    "    # Print results\n",
    "    print(f'Predicted Results: {system_results}')\n",
    "    print(f'Actual Results: {actual_results}')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(actual_results, system_results, pos_label=1)\n",
    "    print(\"False Positive Rate: \", fpr)\n",
    "    print(\"True Positive Rate: \", tpr)\n",
    "    print(\"AUC:\", metrics.auc(fpr, tpr))\n",
    "\n",
    "    \n",
    "    create_subplots(maxhistograms, maxfilename, fpr, tpr, actual_results, system_results)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision(\"original_files\", \"suspicious_files\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
