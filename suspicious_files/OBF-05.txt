We present YOLO as a new approach to object detection. Unlike previous work that repurposes classifiers, YOLO frames object detection as a regression problem for spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images, making the detection pipeline a single network that can be optimized end-to-end for detection performance. The unified architecture is incredibly fast, with the base YOLO model processing images in real-time at 45 frames per second. The smaller Fast YOLO network processes 155 frames per second while achieving double the mAP of other real-time detectors. Although YOLO has more localization errors compared to state-of-the-art detection systems, it is less likely to predict false positives on the background.